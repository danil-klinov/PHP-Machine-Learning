3. ВЕРОЯТНОСТНОЕ МОДЕЛИРОВАНИЕ ТЕМ И ПРИМЕНЕНИЕ ЭТОЙ МОДЕЛИ ДЛЯ ВИЗУАЛИЗАЦИИ КОЛЛЕКЦИЙ ДОКУМЕНТОВ 
В основе методов вероятностного моделирования тем лежит предположе- ние о том, что существует конечное множество тем T, и каждое употребление термина w в каждом документе d связано с некоторой темой t∈T, которая не из- вестна. Коллекция документов рассматривается как множество троек (d, w, t), выбранных случайно и независимо из дискретного распределения p(d, w, t), за- данного на конечном множестве D × W ×T. Документы d∈D и термины w∈W яв- ляются наблюдаемыми переменными, тема t∈T является латентной (скрытой) переменной. Порождающая модель вероятностного моделирования определяет про- стую вероятностную процедуру, которая описывает, как слова в документах мо- гут создаваться на основе скрытых (случайных) переменных. Чтобы создать но- вый документ, надо выбрать распределение по темам. Тогда для добавления каждого нового слова в этот документ случайным образом выбирается тема в соответствии с этим распределением, и затем извлекается слово из этой темы. 
Чтобы инвертировать этот процесс, то есть построить тематическую мо- дель коллекции документов, надо найти множество тем T, распределения p(w|t) для всех тем t∈T и распределения p(t|d) для всех документов d∈D. Это значит, что надо найти наилучший набор скрытых переменных, которые могут объяс- нить наблюдаемые данные (т. е. наблюдаемые слова в документах) в предпо- ложении, что эти данные были сгенерированы при помощи этой порождающей модели. На Рис. 3 показан пример [27] порождающего процесса и процесса ве- роятностного моделирования. Предположим, что коллекция документов по- рождается на основе двух тем (TOPIC1 и TOPIC2). Тема 1 связана с понятием «деньги», а тема 2 – с понятием «река». Поэтому одно и то же слово bank имеет в этих темах разный смысл. Если в теме 1 слово bank понимается как банк, в ко- тором хранятся деньги, то во второй теме оно имеет смысл «берег реки». 
Процедура порождения коллекции документов состоит в выборе различ- ных слов из темы в зависимости от веса, заданного каждой теме. Например, до- кумент DOC1 был получен путем отбора слов только из темы 1, а документ DOC3 – выбором слов только из темы 2, в то время как документ DOC2 был сформиро- ван сочетанием двух тем в равных пропорциях. Надстрочные номера, связанные со словами в документах, указывают, какая из тем была использована для вы- борки слова. 
В данном определении модели нет требования взаимной исключи- тельности тем, которая позволяла бы словам быть частью только одной темы. Это позволяет тематическим моделям описывать многозначность, когда одно и то же слово может иметь несколько значений. Например, обе темы, и первая тема, связанная с деньгами, и вторая, связанная с реками, могут с высокой веро- ятностью содержать слово “bank”, что разумно, учитывая многозначный харак- тер этого слова. На Рис. 3(б) показан пример задачи вероятностного вывода, ре- шаемой для того, чтобы определить распределения тем в коллекции докумен- тов. 
На Рис. 4 показан пример четырех тем, выделенных из коллекции доку- ментов при помощи вероятностного вывода [27]. Как правило, темы, вычислен- ные при помощи метода LDA, обладают свойством хорошей интерпретируемо- сти, то есть слова, принадлежащие одной теме, легко обобщить. 
